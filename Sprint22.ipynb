{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sprint22.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "89jpSljyFQia"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xMWdGfVGdN3"
      },
      "source": [
        "# Problem 1 Forward propagation implementation of SimpleRNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ut_o2xdmFy97"
      },
      "source": [
        "class SimpleRNN:\n",
        "    def __init__(self, n_nodes, initializer, optimizer, activation, debug=False):\n",
        "       #Create node optimization / initialization instance\n",
        "        self.optimizer = optimizer\n",
        "        self.initializer = initializer\n",
        "        self.activation  = activation\n",
        "\n",
        "        self.n_nodes = n_nodes\n",
        "        self.debug = debug\n",
        "\n",
        "        #Initialize node bias\n",
        "        if self.debug:\n",
        "          self.b = np.array([1, 1, 1, 1])\n",
        "        else:\n",
        "          self.b = self.initializer.B(n_nodes, )\n",
        "\n",
        "    def forward(self, X):\n",
        "        \"\"\"\n",
        "        X: Input (batch_size, n_sequences, n_features)\n",
        "\n",
        "        \"\"\"\n",
        "        batch_size  = X.shape[0]\n",
        "        n_sequences = X.shape[1]\n",
        "        n_features  = X.shape[2]\n",
        "\n",
        "        if self.debug:\n",
        "          self.w_x = np.array([[1, 3, 5, 7], [3, 5, 7, 8]])/100\n",
        "          self.w_h = np.array([[1, 3, 5, 7], [2, 4, 6, 8], [3, 5, 7, 8], [4, 6, 8, 10]])/100\n",
        "        else:\n",
        "          self.w_x = self.initializer.W(n_features, self.n_nodes)\n",
        "          self.w_h = self.initializer.W(self.n_nodes, self.n_nodes)\n",
        "\n",
        "        h = np.zeros((n_sequences+1, batch_size, self.n_nodes))\n",
        "\n",
        "        for i in range(n_sequences):\n",
        "           a = X[:, i, :] @ self.w_x + h[i, :, :] @ self.w_h + self.b\n",
        "           h[i+1, :, :] = self.activation.forward(a)\n",
        "        print(h)\n",
        "        return h[-1, :, :]\n",
        "\n",
        "    def backward(self, dA):\n",
        "        \"\"\"\n",
        "        No implementation\n",
        "        \"\"\"\n",
        "        \n",
        "        return dZ\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bh117X0oGwO5"
      },
      "source": [
        "#Initialization class\n",
        "class SimpleInitializer:\n",
        "    def __init__(self, sigma):\n",
        "        self.sigma = sigma\n",
        "        \n",
        "    def W(self, n_nodes1, n_nodes2):\n",
        "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
        "        return W\n",
        "    \n",
        "    def B(self, n_nodes2):\n",
        "        B = self.sigma * np.random.randn(n_nodes2, )\n",
        "        return B"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7XUzZFyO8uo"
      },
      "source": [
        "#Optimization method\n",
        "class SGD:\n",
        "    def __init__(self, lr):\n",
        "        self.lr = lr\n",
        "    def update(self, layer):\n",
        "        layer.B -= self.lr * layer.dB\n",
        "        layer.W -= self.lr * layer.dW"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJcDHjFlPGit"
      },
      "source": [
        "#Activation function\n",
        "class Sigmoid:\n",
        "    \"\"\"\n",
        "    Sigmoid function class\n",
        "    \"\"\"  \n",
        "    def __init__(self):\n",
        "        pass\n",
        "    \n",
        "    def forward(self, X):\n",
        "        self.A = X\n",
        "        return 1 / (1 + np.exp(-X))\n",
        "    \n",
        "    def backward(self, X):\n",
        "        return X * (1- self.forward(self.A)) * self.forward(self.A)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPOvdn5iPP5W"
      },
      "source": [
        "class Tanh:\n",
        "    \"\"\"\n",
        "    Tanh function class\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    \n",
        "    def forward(self, X):\n",
        "        self.A = X\n",
        "        return np.tanh(X)\n",
        "    \n",
        "    def backward(self, X):\n",
        "        return X * (1 - self.forward(self.A)**2)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-xTGCGMPYkw"
      },
      "source": [
        "class Softmax:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    \n",
        "    def forward(self, X):\n",
        "        X = X - np.max(X)\n",
        "        return np.exp(X) / np.sum(np.exp(X), axis=1, keepdims=True)\n",
        "    \n",
        "    def backward(self, X, y):\n",
        "        batch_size = len(X)\n",
        "        delta = 1e-7\n",
        "        \n",
        "        self.loss = -np.sum(y * np.log(X+delta)) / batch_size\n",
        "        return X - y"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tieEDNCDPmoc"
      },
      "source": [
        "class ReLU:\n",
        "    \"\"\"\n",
        "   ReLU function class\n",
        "    \"\"\"\n",
        "    def forward(self, X):\n",
        "        self.A = X\n",
        "        return np.maximum(0, X)\n",
        "    \n",
        "    def backward(self, X):\n",
        "        return X * (self.A > 0)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EG2cNRg1P9Qy"
      },
      "source": [
        "# Problem 2 Experiment of forward propagation with small sequence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9l-Jj0ZPtPP"
      },
      "source": [
        "x = np.array([[[1, 2], [2, 3], [3, 4]]])/100 # (batch_size, n_sequences, n_features)\n",
        "w_x = np.array([[1, 3, 5, 7], [3, 5, 7, 8]])/100 # (n_features, n_nodes)\n",
        "w_h = np.array([[1, 3, 5, 7], [2, 4, 6, 8], [3, 5, 7, 8], [4, 6, 8, 10]])/100 # (n_nodes, n_nodes)\n",
        "batch_size = x.shape[0] # 1\n",
        "n_sequences = x.shape[1] # 3\n",
        "n_features = x.shape[2] # 2\n",
        "n_nodes = w_x.shape[1] # 4\n",
        "h = np.zeros((batch_size, n_nodes)) # (batch_size, n_nodes)\n",
        "b = np.array([1, 1, 1, 1]) # (n_nodes,)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o30w3Uu_QFd0",
        "outputId": "b93db066-f55b-47a1-ef67-22230fdd6c3e"
      },
      "source": [
        "#Calculate only the forward part\n",
        "#1st series\n",
        "activation = Tanh()\n",
        "a1 = x[:, 0, :] @ w_x + h @ w_h + b\n",
        "h1 = activation.forward(a1)\n",
        "#2nd series\n",
        "a2 = x[:, 1, :] @ w_x + h1 @ w_h + b\n",
        "h2 = activation.forward(a2)\n",
        "#3rd series\n",
        "a3 = x[:, 2, :] @ w_x + h2 @ w_h + b\n",
        "h3 = activation.forward(a3)\n",
        "h3\n",
        "\n",
        "print(h1)\n",
        "print(h2)\n",
        "print(h3)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.79483716 0.81815261 0.839056   0.85545658]]\n",
            "[[0.79497284 0.81839951 0.83938892 0.85583371]]\n",
            "[[0.79513154 0.81868106 0.83976521 0.85625949]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVbpCP4NRCaZ",
        "outputId": "a845c328-5a8a-4116-95e4-e6050e034556"
      },
      "source": [
        "#Initialization class\n",
        "initializer = SimpleInitializer(sigma=0.1)\n",
        "#Optimization class\n",
        "optimizer   = SGD(lr=0.1)\n",
        "#Activation function class\n",
        "activation  = Tanh()\n",
        "\n",
        "#Modeling\n",
        "rnn = SimpleRNN(n_nodes, initializer=initializer, optimizer=optimizer, activation=activation, debug=True)\n",
        "rnn.forward(x)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[0.         0.         0.         0.        ]]\n",
            "\n",
            " [[0.76188798 0.76213958 0.76239095 0.76255841]]\n",
            "\n",
            " [[0.792209   0.8141834  0.83404912 0.84977719]]\n",
            "\n",
            " [[0.79494228 0.81839002 0.83939649 0.85584174]]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.79494228, 0.81839002, 0.83939649, 0.85584174]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyEwfKrJTgw4"
      },
      "source": [
        "# Problem 3 (Advance task) Implementation of backpropagation\n",
        "\n",
        "\n",
        "\n",
        "Implement backpropagation.\n",
        "\n",
        "Since the inside of the RNN is a combination of fully connected layers, the update formula is the same as for fully connected layers.\n",
        "\n",
        "No implementation ..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OC5bQCuRcXf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}