{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing liberies or dependencies \n",
    "import time\n",
    "import itertools\n",
    "import re\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from scipy import stats\n",
    "\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROBLEM 1\n",
    "\n",
    "## Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reading or loading CSV data files\n",
    "train = pd.read_csv(\"application_train.csv\")\n",
    "test  = pd.read_csv(\"application_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Selecting the features to be used.\n",
    "feats = ['EXT_SOURCE_1', 'EXT_SOURCE_3', 'EXT_SOURCE_2', 'DAYS_EMPLOYED',\n",
    "         'DAYS_BIRTH', 'AMT_ANNUITY', 'AMT_CREDIT', 'AMT_GOODS_PRICE',\n",
    "         'DAYS_ID_PUBLISH', 'DAYS_REGISTRATION']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Missing values processing performing 0 filling or avarage value filling\n",
    "train[\"EXT_SOURCE_1\"] = train[\"EXT_SOURCE_1\"].fillna(0)\n",
    "train[\"EXT_SOURCE_2\"] = train[\"EXT_SOURCE_1\"].fillna(0)\n",
    "train[\"EXT_SOURCE_3\"] = train[\"EXT_SOURCE_1\"].fillna(0)\n",
    "train[\"AMT_ANNUITY\"] = train[\"AMT_ANNUITY\"].fillna(train[\"AMT_ANNUITY\"].mean())\n",
    "train[\"AMT_GOODS_PRICE\"] = train[\"AMT_GOODS_PRICE\"].fillna(train[\"AMT_GOODS_PRICE\"].mean())\n",
    "\n",
    "test[\"EXT_SOURCE_1\"] = test[\"EXT_SOURCE_1\"].fillna(0)\n",
    "test[\"EXT_SOURCE_2\"] = test[\"EXT_SOURCE_1\"].fillna(0)\n",
    "test[\"EXT_SOURCE_3\"] = test[\"EXT_SOURCE_1\"].fillna(0)\n",
    "test[\"AMT_ANNUITY\"] = test[\"AMT_ANNUITY\"].fillna(test[\"AMT_ANNUITY\"].mean())\n",
    "test[\"AMT_GOODS_PRICE\"] = test[\"AMT_GOODS_PRICE\"].fillna(test[\"AMT_GOODS_PRICE\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[feats]\n",
    "y_train = train[\"TARGET\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average auc_score: 0.6323\n"
     ]
    }
   ],
   "source": [
    "## Cross-validation using Random Forest (K = 2)\n",
    "scores = []\n",
    "\n",
    "kf = KFold(n_splits=2, shuffle=True, random_state=1)\n",
    "for tr_idx, va_idx in kf.split(X_train):\n",
    "    tr_x, va_x = X_train.iloc[tr_idx], X_train.iloc[va_idx]\n",
    "    tr_y, va_y = y_train.iloc[tr_idx], y_train.iloc[va_idx]\n",
    "    \n",
    "    rand = RandomForestClassifier()\n",
    "    rand.fit(tr_x, tr_y)\n",
    "    \n",
    "    pred = rand.predict_proba(va_x)[:, 1]\n",
    "    score = roc_auc_score(va_y, pred)\n",
    "    scores.append(score)\n",
    "    \n",
    "print(\"Average auc_score: %.4f\" % np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROBLEM 2\n",
    "\n",
    "## GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={'max_depth': [3, 5, 7], 'n_estimators': [100, 200]},\n",
       "             return_train_score=True, scoring='roc_auc')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\"n_estimators\":[100, 200],\n",
    "           \"max_depth\":[3, 5, 7]\n",
    "         }\n",
    "\n",
    "grid_search = GridSearchCV(RandomForestClassifier(), params,\n",
    "                           cv=2, n_jobs=-1, return_train_score=True, scoring=\"roc_auc\")\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 7, 'n_estimators': 200}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROBLEM 3\n",
    "\n",
    "## Survey from Kaggle Notebooks. Find and list different ideas from Kaggle's Notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Gradient Boosting Machine: A strong predictive baseline model these days is ligth-gbm.\n",
    "\n",
    "* The time required for model training is short. High memory efficiency because the measured value is treated as a histogram.\n",
    "\n",
    "* Can handle missing values as they are, there is no need to perform conversion processing such as scaling, because the magnitude relationship makes sense.\n",
    "\n",
    "* The number of estimators of the gradient boosting model does not need to be adjusted as a hyperparameter by using early stopping.\n",
    "\n",
    "* The \"Leaf-wise\" format complicates the model and is prone to overfitting if not properly adjusted with hyperparameters.\n",
    "\n",
    "2. Objective function: A function that returns a score that is an index for optimizing hyperparameters. The function you want to minimize / maximize. Auc for binary classification\n",
    "\n",
    "\n",
    "\n",
    "3. Domain: A trial combination of model hyperparameters. That range. See the official documentation\n",
    "\n",
    "\n",
    "\n",
    "4. Algorithm: How to determine the selection of hyperparameters to try. Since humans determine the trial range, it is not always possible to find globally optimized parameters. Very high computational cost to try all combinations. On the contrary, if you try all combinations, you will be able to find an answer that is close to the overall optimal solution.\n",
    "\n",
    "Humans set the trial range, and it is not always possible to find a truly totally optimized combination of parameters.\n",
    "Since the combination of parameters is randomly determined and learning / evaluation is performed, a combination close to the optimum solution can be investigated with a small number of trials.\n",
    "Since it is a random selection, if the number of trials is too low, it may be far from the optimal solution.\n",
    "It is efficient to perform a random search at the beginning, determine the peripheral values ​​of the optimum solution of the parameters, and then perform a grid search.\n",
    "\n",
    "While randomly determining the parameters, repeat learning and evaluation around the highly evaluated parameter combinations to find an answer close to the optimal solution in a short time.\n",
    "\n",
    "\n",
    "5. Execution history: A data structure containing scores obtained from each set and objective function. Easy to understand if made with df."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROBLEM 4\n",
    "\n",
    "## Creating a model with high generalization performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307511, 120)\n",
      "(48744, 121)\n"
     ]
    }
   ],
   "source": [
    "## Reloading of data\n",
    "train = pd.read_csv(\"application_train.csv\")\n",
    "test  = pd.read_csv(\"application_test.csv\")\n",
    "\n",
    "train_x = train.drop([\"TARGET\", \"SK_ID_CURR\"], axis=1)\n",
    "train_y = train[\"TARGET\"]\n",
    "test_x = test.copy()\n",
    "\n",
    "print(train_x.shape)\n",
    "print(test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 columns were label encoded.\n",
      "Training Features shape:  (307511, 241)\n",
      "Testing Features shape:  (48744, 239)\n"
     ]
    }
   ],
   "source": [
    "## Create a label encoder object\n",
    "le = LabelEncoder()\n",
    "le_count = 0\n",
    "\n",
    "## Iterate through the columns\n",
    "for col in train_x:\n",
    "    if train_x[col].dtype == 'object':\n",
    "        ## If 2 or fewer unique categories\n",
    "        if len(list(train[col].unique())) <= 2:\n",
    "            ## Train on the training data\n",
    "            le.fit(train_x[col])\n",
    "            ## Transform both training and testing data\n",
    "            train_x[col] = le.transform(train_x[col])\n",
    "            test_x[col] = le.transform(test_x[col])\n",
    "            \n",
    "            ## Keep track of how many columns were label encoded\n",
    "            le_count += 1\n",
    "            \n",
    "print('%d columns were label encoded.' % le_count)\n",
    "\n",
    "## one-hot encoding of categorical variables\n",
    "train_x = pd.get_dummies(train_x)\n",
    "test_x = pd.get_dummies(test_x)\n",
    "\n",
    "print('Training Features shape: ', train_x.shape)\n",
    "print('Testing Features shape: ', test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features shape:  (307511, 238)\n",
      "Testing Features shape:  (48744, 238)\n"
     ]
    }
   ],
   "source": [
    "train_x, test_x = train_x.align(test_x, join=\"inner\", axis=1)\n",
    "\n",
    "print('Training Features shape: ', train_x.shape)\n",
    "print('Testing Features shape: ', test_x.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the number of data is large, this time we will compare each model using 50,000 rows of train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307511, 238)\n",
      "(307511,)\n",
      "(50000, 238)\n",
      "(50000,)\n"
     ]
    }
   ],
   "source": [
    "## If JSON characters are included in the column name, an error will occur.\n",
    "train_x = train_x.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "test_x  =  test_x.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "\n",
    "\n",
    "## Random state should be described so that the correspondence between x and y does not change.\n",
    "train_x_all = train_x.copy()\n",
    "train_y_all = train_y.copy()\n",
    "\n",
    "n = 50000\n",
    "train_x = train_x.sample(n, random_state=0)\n",
    "train_y = train_y.sample(n, random_state=0)\n",
    "\n",
    "print(train_x_all.shape)\n",
    "print(train_y_all.shape)\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create training data and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_x, train_y, test_size=0.25, random_state=1)\n",
    "\n",
    "## lgb Create a dataset for learning\n",
    "train_set = lgb.Dataset(data = X_train, label = y_train)\n",
    "test_set = lgb.Dataset(data = X_test, label = y_test)\n",
    "train_test_set = lgb.Dataset(data = train_x, label = train_y)\n",
    "\n",
    "## Create df for storing results\n",
    "results = pd.DataFrame(columns=[\"Andy\", \"Train_Time\", \"Val_Score\", \"Test_Score\", \"keggle_Score\"],\n",
    "           index=list(range(7)))\n",
    "\n",
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Andy</th>\n",
       "      <th>Train_Time</th>\n",
       "      <th>Val_Score</th>\n",
       "      <th>Test_Score</th>\n",
       "      <th>keggle_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>not cv</td>\n",
       "      <td>7.55708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.727502</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Andy Train_Time Val_Score Test_Score keggle_Score\n",
       "0  not cv    7.55708       NaN   0.727502          NaN\n",
       "1     NaN        NaN       NaN        NaN          NaN\n",
       "2     NaN        NaN       NaN        NaN          NaN\n",
       "3     NaN        NaN       NaN        NaN          NaN\n",
       "4     NaN        NaN       NaN        NaN          NaN\n",
       "5     NaN        NaN       NaN        NaN          NaN\n",
       "6     NaN        NaN       NaN        NaN          NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## 1. No cross-validation\n",
    "model = lgb.LGBMClassifier()\n",
    "default_params = model.get_params()\n",
    "\n",
    "## Exclude the number of classifiers from hyperparameters ⇒ For early stopping\n",
    "del default_params[\"n_estimators\"]\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "t = time.time() - start\n",
    "\n",
    "preds = model.predict_proba(X_test)[:, 1]\n",
    "auc = roc_auc_score(y_test, preds)\n",
    "\n",
    "results.loc[i, :] = [\"not cv\", t, np.nan, auc, np.nan]\n",
    "i += 1\n",
    "\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.050816 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10808\n",
      "[LightGBM] [Info] Number of data points in the train set: 28125, number of used features: 219\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025034 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10808\n",
      "[LightGBM] [Info] Number of data points in the train set: 28125, number of used features: 219\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.075472 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10808\n",
      "[LightGBM] [Info] Number of data points in the train set: 28125, number of used features: 219\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.055386 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10808\n",
      "[LightGBM] [Info] Number of data points in the train set: 28125, number of used features: 219\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Info] Start training from score 0.078507\n",
      "[LightGBM] [Info] Start training from score 0.078471\n",
      "[LightGBM] [Info] Start training from score 0.078471\n",
      "[LightGBM] [Info] Start training from score 0.078471\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030957 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10808\n",
      "[LightGBM] [Info] Number of data points in the train set: 33333, number of used features: 219\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.091927 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10808\n",
      "[LightGBM] [Info] Number of data points in the train set: 33333, number of used features: 219\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033393 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10808\n",
      "[LightGBM] [Info] Number of data points in the train set: 33333, number of used features: 219\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.105282 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10808\n",
      "[LightGBM] [Info] Number of data points in the train set: 33333, number of used features: 219\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019436 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10808\n",
      "[LightGBM] [Info] Number of data points in the train set: 33333, number of used features: 219\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.077379 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10808\n",
      "[LightGBM] [Info] Number of data points in the train set: 33333, number of used features: 219\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050641 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10808\n",
      "[LightGBM] [Info] Number of data points in the train set: 33334, number of used features: 219\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027319 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10808\n",
      "[LightGBM] [Info] Number of data points in the train set: 33334, number of used features: 219\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030579 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10808\n",
      "[LightGBM] [Info] Number of data points in the train set: 33334, number of used features: 219\n",
      "[LightGBM] [Warning] Unknown parameter: importance_type\n",
      "[LightGBM] [Warning] Unknown parameter: silent\n",
      "[LightGBM] [Info] Start training from score 0.078481\n",
      "[LightGBM] [Info] Start training from score 0.078481\n",
      "[LightGBM] [Info] Start training from score 0.078481\n",
      "[LightGBM] [Info] Start training from score 0.078481\n",
      "[LightGBM] [Info] Start training from score 0.078481\n",
      "[LightGBM] [Info] Start training from score 0.078481\n",
      "[LightGBM] [Info] Start training from score 0.078478\n",
      "[LightGBM] [Info] Start training from score 0.078478\n",
      "[LightGBM] [Info] Start training from score 0.078478\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Andy</th>\n",
       "      <th>Train_Time</th>\n",
       "      <th>Val_Score</th>\n",
       "      <th>Test_Score</th>\n",
       "      <th>keggle_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>not cv</td>\n",
       "      <td>7.55708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.727502</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cv(k=4)</td>\n",
       "      <td>18.4874</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.737986</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cv(k=9)</td>\n",
       "      <td>30.8559</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.739489</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Andy Train_Time Val_Score Test_Score keggle_Score\n",
       "0   not cv    7.55708       NaN   0.727502          NaN\n",
       "1  cv(k=4)    18.4874       NaN   0.737986          NaN\n",
       "2  cv(k=9)    30.8559       NaN   0.739489          NaN\n",
       "3      NaN        NaN       NaN        NaN          NaN\n",
       "4      NaN        NaN       NaN        NaN          NaN\n",
       "5      NaN        NaN       NaN        NaN          NaN\n",
       "6      NaN        NaN       NaN        NaN          NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## 2 Perform cross-validation (k = 4.9)\n",
    "andy = {\"cv(k=4)\": 4, \"cv(k=9)\": 9}\n",
    "\n",
    "for andy, cv in andy.items():\n",
    "    \n",
    "    start = time.time()\n",
    "    cv_result = lgb.cv(default_params, train_set, num_boost_round=10000,\n",
    "                       early_stopping_rounds=100, metrics=\"auc\", nfold=cv, seed=1)\n",
    "    t = time.time() - start\n",
    "    \n",
    "    results.loc[i, :] = [andy, t, np.nan, cv_result[\"auc-mean\"][-1], np.nan]\n",
    "    i += 1\n",
    "    \n",
    "display(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROBLEM 5\n",
    "\n",
    "## Final model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Andy</th>\n",
       "      <th>Train_Time</th>\n",
       "      <th>Val_Score</th>\n",
       "      <th>Test_Score</th>\n",
       "      <th>keggle_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>not cv</td>\n",
       "      <td>7.55708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.727502</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cv(k=4)</td>\n",
       "      <td>18.4874</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.737986</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cv(k=9)</td>\n",
       "      <td>30.8559</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.739489</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Andy Train_Time Val_Score Test_Score keggle_Score\n",
       "0   not cv    7.55708       NaN   0.727502          NaN\n",
       "1  cv(k=4)    18.4874       NaN   0.737986          NaN\n",
       "2  cv(k=9)    30.8559       NaN   0.739489          NaN\n",
       "3      NaN        NaN       NaN        NaN          NaN\n",
       "4      NaN        NaN       NaN        NaN          NaN\n",
       "5      NaN        NaN       NaN        NaN          NaN\n",
       "6      NaN        NaN       NaN        NaN          NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in the results in the table above, using Bayesian optimization for the light-gbm model resulted in the model with the highest generalization performance. In addition, this time, we compared the scores at the time of verification using training data of 50,000 samples, and the larger the number of cross-validation division."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
